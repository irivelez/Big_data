{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a952ad54-2218-4382-b2eb-d401d349f764",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"../../../banner.jpg\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6bc19",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/BDML_SS/blob/main/Lecture05/Notebook_SS05/Notebook_SS05_CV.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e57de4",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "\n",
    ".responsive {\n",
    " width: 100%;\n",
    " height: 25%;\n",
    "}\n",
    "\n",
    ".list-group-item.active, .list-group-item.active:focus, .list-group-item.active:hover {\n",
    "    z-index: 2;\n",
    "    color: #fff;\n",
    "    background-color: #1B175E;\n",
    "    border-color: #337ab7;\n",
    "}\n",
    "h1, h2, h3, h4 {\n",
    "    color: #000002;\n",
    "    background-color: #1B175E;\n",
    "    background-image:\n",
    "      linear-gradient(to right,\n",
    "       #fff, #ffff00\n",
    "     );\n",
    "\n",
    "}\n",
    "\n",
    "h1, h2, h3, h4, p {\n",
    "    color: #000002;\n",
    "}\n",
    "\n",
    "a {\n",
    "    color: #1B175E;\n",
    "}\n",
    "</style>\n",
    "\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efaa5f-efe9-424e-bf07-c46550bc67fb",
   "metadata": {},
   "source": [
    "The concept behind resampling techniques for evaluating model performance is straightforward: a portion of the data is used to train the model, while the remaining data is used to assess the model's accuracy. \n",
    "\n",
    "This process is repeated several times with different subsets of the data, and the results are averaged and summarized. The primary differences between resampling techniques lie in the method by which the subsets of data are selected. \n",
    "\n",
    "In the following sections, we will discuss the main types of resampling techniques.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a3dcd",
   "metadata": {},
   "source": [
    "# Predicting Wages\n",
    "\n",
    "Our objective today is to construct a model of individual wages\n",
    "\n",
    "$$\n",
    "w = f(X) + u \n",
    "$$\n",
    "\n",
    "where w is the  wage, and X is a matrix that includes potential explanatory variables/predictors. In this problem set, we will focus on a linear model of the form\n",
    "\n",
    "\\begin{align}\n",
    " ln(w) & = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p  + u \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ba2f4",
   "metadata": {},
   "source": [
    "were $ln(w)$ is the logarithm of the wage.\n",
    "\n",
    "To illustrate I'm going to use a sample of the NLSY97. The NLSY97 is  a nationally representative sample of 8,984 men and women born during the years 1980 through 1984 and living in the United States at the time of the initial survey in 1997.  Participants were ages 12 to 16 as of December 31, 1996.  Interviews were conducted annually from 1997 to 2011 and biennially since then.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdab5a6",
   "metadata": {},
   "source": [
    "Let's load the packages and the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e94ec2b-ab94-4ec8-8512-e370d2f22a56",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: pacman\n",
      "\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m1266\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m994\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (994): lnw_2016, educ, black, hispanic, other, exp, afqt, mom_educ, dad_...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "#packages\n",
    "require(\"pacman\")\n",
    "p_load(\"tidyverse\",\"stargazer\")\n",
    "\n",
    "nlsy <- read_csv('https://raw.githubusercontent.com/ignaciomsarmiento/datasets/main/nlsy97.csv')\n",
    "\n",
    "nlsy = nlsy  %>%   drop_na(educ) #dropea los valores faltantes (NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2532d7",
   "metadata": {},
   "source": [
    "# Validation Set  Approach\n",
    "\n",
    "The first method to evaluate out-of-sample performance is the validation set approach. In this approach, a fixed portion of the data is designated as the validation set, and the model is trained on the remaining data. The model's performance is then evaluated on the validation set. These partitions are usually called:\n",
    "\n",
    "   - Training sample: to build/estimate/train the model\n",
    "   - Testing (validation, hold-out) sample:  to evaluate its performance \n",
    "\n",
    "Partitions can be of any size. Usually, 70%-30% or 80%-20% are used. Graphically, a 70%-30% partition looks like:     \n",
    "    \n",
    "<div>\n",
    "<img src=\"30-70.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88212caa",
   "metadata": {},
   "source": [
    "Let's implement this in `R`.\n",
    "\n",
    "We begin by generating a sample index that will indicate with `TRUE` those observations randomly assigned to the training data set with 70% probability, and with `FALSE` those observations randomly assigned to the testing data set with 30% chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acae014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>TRUE</li><li>FALSE</li><li>TRUE</li><li>FALSE</li><li>FALSE</li><li>TRUE</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\item FALSE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. FALSE\n",
       "3. TRUE\n",
       "4. FALSE\n",
       "5. FALSE\n",
       "6. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  TRUE FALSE  TRUE FALSE FALSE  TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make this example reproducible\n",
    "set.seed(123)\n",
    "\n",
    "#use 70% of the dataset as a training set and 30% as a test set\n",
    "sample <- sample(c(TRUE, FALSE), nrow(nlsy), replace=TRUE, prob=c(0.7,0.3))\n",
    "head(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b63d02",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "we can check that the partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df09eb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.70695102685624"
      ],
      "text/latex": [
       "0.70695102685624"
      ],
      "text/markdown": [
       "0.70695102685624"
      ],
      "text/plain": [
       "[1] 0.706951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(sample)/nrow(nlsy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbea998",
   "metadata": {},
   "source": [
    "With the above index, we generate the partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9d0077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>895</li><li>994</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 895\n",
       "\\item 994\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 895\n",
       "2. 994\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 895 994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train  <- nlsy[sample, ] #train sample those that are TRUE in the sample index\n",
    "test   <- nlsy[!sample, ] #test sample those that are FALSE in the sample index\n",
    "dim(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1318f0-248e-41cf-b5c6-3a9fec9f9d99",
   "metadata": {},
   "source": [
    "## Predicting wages\n",
    "\n",
    "With these partitions in place, we can start building our predictive models. We begin by using a simple model with no covariates, just a constant:\n",
    "\n",
    "$$\n",
    "ln(w)= \\beta_0 + u\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a201763-d401-4f93-866a-00d1a6dc87c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lnw_2016 ~ 1, data = train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-5.0668 -0.4639 -0.0127  0.4138  4.2818 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  3.11143    0.02847   109.3   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.8519 on 894 degrees of freedom\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1<-lm(lnw_2016~1,data=train)\n",
    "summary(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980df5e-4174-45bb-9b0f-13b558828a0b",
   "metadata": {},
   "source": [
    "In this case, the prediction for the log wage is the average train sample average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ad357-a9c5-4be6-9a38-e379229878b3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y}=\\hat{\\beta}_0=\\frac{\\sum y_i}{n}=m\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fa8942-e1b3-48d1-8d75-a9a2dcfb3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>(Intercept):</strong> 3.11142668361229"
      ],
      "text/latex": [
       "\\textbf{(Intercept):} 3.11142668361229"
      ],
      "text/markdown": [
       "**(Intercept):** 3.11142668361229"
      ],
      "text/plain": [
       "(Intercept) \n",
       "   3.111427 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bed4174",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Coef: 3.11142668361229'"
      ],
      "text/latex": [
       "'Coef: 3.11142668361229'"
      ],
      "text/markdown": [
       "'Coef: 3.11142668361229'"
      ],
      "text/plain": [
       "[1] \"Coef: 3.11142668361229\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste(\"Coef:\", mean(train$lnw_2016))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e78c6-94e3-4646-b96b-269fcffcee7b",
   "metadata": {},
   "source": [
    "Since we are concerned with predicting well out-of -sample, we need to evaluate our model in the testing data. For that, we use the coefficient estimated in the training data and use it as a predictor in the testing data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f900622",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y}_{test} = \\hat{\\beta}_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbea972-26d5-48a1-a322-9c0a942703a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on new data\n",
    "test$yhat_model1<-predict(model1,newdata = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77839d42-8882-4761-8db4-df6bc614f3ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then we can calculate the out-of-sample performance using the MSE:\n",
    "\n",
    "$$\n",
    "test\\,MSE=E((y_{test}-\\hat{y}_{test})^2)\n",
    "$$ \n",
    "in `R`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158d9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.827608103583473"
      ],
      "text/latex": [
       "0.827608103583473"
      ],
      "text/markdown": [
       "0.827608103583473"
      ],
      "text/plain": [
       "[1] 0.8276081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(test,mean((lnw_2016-yhat_model1)^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd03f2",
   "metadata": {},
   "source": [
    "This is quite a naive model that uses the sample average as a prediction. \n",
    "\n",
    "Let's see if we can improve (reduce the prediction error) this model.\n",
    "\n",
    "To improve our prediction, we can start adding explanatory variables. Let's begin by adding only one variable,  `education (educ)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb0842",
   "metadata": {},
   "source": [
    "$$\n",
    "ln(w)= \\beta_0 + \\beta_1 Educ+ u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c6ac7",
   "metadata": {},
   "source": [
    "We estimate this model on the train sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe39dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2<-lm(lnw_2016~educ,data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8e6bf",
   "metadata": {},
   "source": [
    "Let's predict out-of-sample:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0 + \\hat{\\beta}_1 * Educ_{test} = \\hat{y}_{test}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c17ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test$yhat_model2<-predict(model2,newdata = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d11ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "and evaluate the  out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9cac15-8f34-4962-9bf1-c3a680bd6f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.796370489870419"
      ],
      "text/latex": [
       "0.796370489870419"
      ],
      "text/markdown": [
       "0.796370489870419"
      ],
      "text/plain": [
       "[1] 0.7963705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(test,mean((lnw_2016-yhat_model2)^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3318f53",
   "metadata": {},
   "source": [
    "If I wanted to do this by hand? I need\n",
    "\n",
    "1. The function trained on the train set, i.e., $\\hat{\\beta}_0$, $\\hat{\\beta}_1$\n",
    "2. The observables form the test set, i.e., $Educ_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd535bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>1.92662044070487</dd><dt>educ</dt><dd>0.082547219944118</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 1.92662044070487\n",
       "\\item[educ] 0.082547219944118\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   1.92662044070487educ\n",
       ":   0.082547219944118\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)        educ \n",
       " 1.92662044  0.08254722 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefs<-model2$coefficients\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59379aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>9</li><li>16</li><li>16</li><li>16</li><li>16</li><li>18</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 9\n",
       "\\item 16\n",
       "\\item 16\n",
       "\\item 16\n",
       "\\item 16\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 9\n",
       "2. 16\n",
       "3. 16\n",
       "4. 16\n",
       "5. 16\n",
       "6. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  9 16 16 16 16 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "educ_test<-test$educ\n",
    "head(educ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20259073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>2.66954542020193</li><li>3.24737595981076</li><li>3.24737595981076</li><li>3.24737595981076</li><li>3.24737595981076</li><li>3.412470399699</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2.66954542020193\n",
       "\\item 3.24737595981076\n",
       "\\item 3.24737595981076\n",
       "\\item 3.24737595981076\n",
       "\\item 3.24737595981076\n",
       "\\item 3.412470399699\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2.66954542020193\n",
       "2. 3.24737595981076\n",
       "3. 3.24737595981076\n",
       "4. 3.24737595981076\n",
       "5. 3.24737595981076\n",
       "6. 3.412470399699\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2.669545 3.247376 3.247376 3.247376 3.247376 3.412470"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat_test<-coefs[1]+coefs[2]*educ_test\n",
    "head(yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd4ca8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.796370489870419"
      ],
      "text/latex": [
       "0.796370489870419"
      ],
      "text/markdown": [
       "0.796370489870419"
      ],
      "text/plain": [
       "[1] 0.7963705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean((test$lnw_2016-yhat_test)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311451b-4af0-4638-a834-fa921cee1c71",
   "metadata": {},
   "source": [
    "There's a clear disminution in MSE. Let's add complexity by adding more variables:\n",
    "\n",
    "$$\n",
    "ln(w)= \\beta_0 + \\beta_1 Educ + \\beta_2 Exp + \\beta_3 AFQT + \\beta_4 Educ\\,Madre+ \\beta_5 Educ\\,Padre  + u\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c152233-8bda-4e61-9853-160fb7790093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3<-lm(lnw_2016~educ + exp + afqt + mom_educ + dad_educ,data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80e77a",
   "metadata": {},
   "source": [
    "Prediction out-of-sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d09708dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test$yhat_model3<-predict(model3,newdata = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ccf7b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e06f8287-7756-4d88-99a2-2eb1285007fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.788165936471574"
      ],
      "text/latex": [
       "0.788165936471574"
      ],
      "text/markdown": [
       "0.788165936471574"
      ],
      "text/plain": [
       "[1] 0.7881659"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(test,mean((lnw_2016-yhat_model3)^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129749c0-3299-475d-9448-8b8d194c253e",
   "metadata": {},
   "source": [
    "In this case, the MSE keeps improving. Is there a limit to this improvement? Can we keep adding features and complexity? What about an extremely complex model that includes polynomials and interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5fc101d-6211-40d9-8dc2-4e2f8580d568",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model4<-lm(lnw_2016~poly(educ,8,raw=TRUE):poly(exp,3,raw=TRUE):\n",
    "           poly(afqt,3,raw=TRUE)+ poly(mom_educ,3,raw=TRUE):\n",
    "           poly(dad_educ,3,raw=TRUE) +\n",
    "           black+hispanic + other,data=train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a5057",
   "metadata": {},
   "source": [
    "Prediction out-of-sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3c4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "test$yhat_model4<-predict(model4,newdata = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f22665",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "327d5853-5364-4865-8854-3066623e0517",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.933888212716992"
      ],
      "text/latex": [
       "0.933888212716992"
      ],
      "text/markdown": [
       "0.933888212716992"
      ],
      "text/plain": [
       "[1] 0.9338882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with(test,mean((lnw_2016-yhat_model4)^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb15c3-aff7-4fd0-8229-6b5d654396ce",
   "metadata": {},
   "source": [
    "Le'ts put all these performance resuls in a table and compare them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea94d4c",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 4 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>MSE</th></tr>\n",
       "\t<tr><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>model1</td><td>0.828</td></tr>\n",
       "\t<tr><td>model2</td><td>0.796</td></tr>\n",
       "\t<tr><td>model3</td><td>0.788</td></tr>\n",
       "\t<tr><td>model4</td><td>0.934</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4 × 2\n",
       "\\begin{tabular}{ll}\n",
       " model & MSE\\\\\n",
       " <ord> & <dbl>\\\\\n",
       "\\hline\n",
       "\t model1 & 0.828\\\\\n",
       "\t model2 & 0.796\\\\\n",
       "\t model3 & 0.788\\\\\n",
       "\t model4 & 0.934\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4 × 2\n",
       "\n",
       "| model &lt;ord&gt; | MSE &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| model1 | 0.828 |\n",
       "| model2 | 0.796 |\n",
       "| model3 | 0.788 |\n",
       "| model4 | 0.934 |\n",
       "\n"
      ],
      "text/plain": [
       "  model  MSE  \n",
       "1 model1 0.828\n",
       "2 model2 0.796\n",
       "3 model3 0.788\n",
       "4 model4 0.934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create vars with all the MSE\n",
    "mse1<-with(test,round(mean((lnw_2016-yhat_model1)^2),3))\n",
    "mse2<-with(test,round(mean((lnw_2016-yhat_model2)^2),3))\n",
    "mse3<-with(test,round(mean((lnw_2016-yhat_model3)^2),3))\n",
    "mse4<-with(test,round(mean((lnw_2016-yhat_model4)^2),3))\n",
    "\n",
    "#put them in a vector\n",
    "mse<-c(mse1,mse2,mse3,mse4)\n",
    "\n",
    "#create a data frame\n",
    "db<-data.frame(model=factor(c(\"model1\",\"model2\",\"model3\",\"model4\"),ordered=TRUE),\n",
    "               MSE=mse)\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0149927-e250-4ba5-94b0-0a76bf6428a9",
   "metadata": {},
   "source": [
    "It is clear that as complexity increases, performance improves until a point where too much complexity results in inferior performance. \n",
    "\n",
    "This is an illustration of the Bias-Variance-Trade-Off.\n",
    "\n",
    "Although the validation set approach is quite nice, there are at least two problems with it:\n",
    "  \n",
    "  1. The first one is that given an original data set if part of it is left aside to test the model, fewer data is left for estimation (leading to less efficiency).\n",
    "  2. A second problem is deciding which data will be used to train the model and which one to test it\n",
    "\n",
    "# Leave-One-Out Cross-Validation (LOOCV) \n",
    "\n",
    "This method is similar to the Validation Set Approach, but it tries to address the latter's disadvantages. Leave-One-Out Cross-Validation (LOOCV) is a resampling technique for evaluating model performance. Each sample in the data is used once as the validation set, and the model is trained on the remaining samples. \n",
    "\n",
    "Graphically the LOOCV looks like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d07a19",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "<img src=\"1.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"3.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "<div>\n",
    "<img src=\"20.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "LOOCV is computationally expensive, as a separate model has to be fit `n` times, where `n` is the number of samples in the data. However, LOOCV is more thorough in its model evaluation, as each sample is used as the validation set exactly once, giving a more comprehensive assessment of the model's performance.\n",
    "\n",
    "The LOOCV estimate for the test MSE is\n",
    "\n",
    "\\begin{align}\n",
    "LOOCV(n) &= \\frac{1}{n}\\sum MSE_{-i} \\\\ \n",
    "      &= \\frac{1}{n}\\sum(y_i -\\hat{y}_{-i})^2\n",
    "\\end{align}\n",
    "\n",
    "where $-i$ indicates that the model to obtain the prediction was trained in all observations except $i$.\n",
    "\n",
    "LOOCV is particularly useful in cases where the number of samples in the data is small, and the risk of overfitting is high. LOOCV is a special case of k-fold cross-validation, where k is equal to the number of samples in the data. Given that it's a particular case of k-fold cross-validation, we will implement this in `R` instead.\n",
    "\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "\n",
    "K-Fold Cross-Validation  is a widely used resampling technique for evaluating model performance. It involves dividing the data into k equally sized folds, where k is a user-defined constant. The model is then fit k times, with each fold used once as the validation set and the remaining k-1 folds used as the training set. This process results in k estimates of the model's performance, which can then be averaged to obtain an overall estimate. Graphically it looks like this:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"fold.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "K-Fold Cross-Validation is a trade-off between the computational efficiency of the validation set approach and the thoroughness of LOOCV. \n",
    "\n",
    "On the one hand, K-Fold Cross-Validatio is more computationally efficient than LOOCV, as the model is fit k times instead of n times, where n is the number of samples in the data. \n",
    "\n",
    "On the other hand, K-Fold Cross-Validation is less thorough than LOOCV, as each sample is used in the validation set k-1/k of the time, giving a less comprehensive assessment of the model's performance. However, K-Fold Cross-Validation is widely used in practice. \n",
    "\n",
    "It provides a good balance between computational efficiency and thoroughness while allowing the user to control the number of times the model fits.\n",
    "\n",
    "K-Fold Cross-Validation provides a more robust evaluation of the model's performance than the validation set approach.  In the validation set approach, a fixed portion of the data is used as the validation set, which can result in a suboptimal estimation of the model's performance if the validation set is not representative of the data. In contrast, K-Fold Cross-Validatio ensures that each sample is used in the validation set exactly once, providing a more comprehensive assessment of the model's performance.\n",
    "\n",
    "To sum up, to implement K-Fold Cross-Validation, we need to:\n",
    "\n",
    "- Split the data into K parts $(n=\\sum_{j=1}^k n_j)$\n",
    "\n",
    "- Fit the model leaving out one of the folds $\\rightarrow$ $\\hat{y}_{-k}$\n",
    "  \n",
    "- Cycle through all k folds\n",
    " \n",
    "-  The CV(k) estimate for the test MSE is\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "CV_{(k)} &= \\frac{1}{k}\\sum_{j=1}^k MSE_j \\\\\n",
    "         &= \\frac{1}{k}\\sum_{j=1}^k (y_j^k-\\hat{y}_{-k})^{2}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Let's implement it in `R`\n",
    "\n",
    "### Splitting the data into K folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a0bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in split.default(1:nrow(nlsy), 1:K):\n",
      "“data length is not a multiple of split variable”\n"
     ]
    }
   ],
   "source": [
    "#Make this example reproducible\n",
    "set.seed(0101)\n",
    "\n",
    "# Specify the number of folds for\n",
    "# 5-fold cross-validation\n",
    "K <- 5\n",
    "\n",
    "#Split the data set into 5 folds\n",
    "index <- split(1:nrow(nlsy), 1: K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb8257",
   "metadata": {},
   "source": [
    "We used the `split` function to generate a list with indexes that will help split the dataset into 5 parts of roughly equal size. We can see the first six indexes of the observations randomly assigned to the first partition or fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48128eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1</li><li>6</li><li>11</li><li>16</li><li>21</li><li>26</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 6\n",
       "\\item 11\n",
       "\\item 16\n",
       "\\item 21\n",
       "\\item 26\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 6\n",
       "3. 11\n",
       "4. 16\n",
       "5. 21\n",
       "6. 26\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  1  6 11 16 21 26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(index[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9108e",
   "metadata": {},
   "source": [
    "Given that the size is not divisible by 5 `R` sometimes give us a *Warning*, we can verify the length of each partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01c5bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$`1`</dt>\n",
       "\t\t<dd>254</dd>\n",
       "\t<dt>$`2`</dt>\n",
       "\t\t<dd>253</dd>\n",
       "\t<dt>$`3`</dt>\n",
       "\t\t<dd>253</dd>\n",
       "\t<dt>$`4`</dt>\n",
       "\t\t<dd>253</dd>\n",
       "\t<dt>$`5`</dt>\n",
       "\t\t<dd>253</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$`1`] 254\n",
       "\\item[\\$`2`] 253\n",
       "\\item[\\$`3`] 253\n",
       "\\item[\\$`4`] 253\n",
       "\\item[\\$`5`] 253\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$`1`\n",
       ":   254\n",
       "$`2`\n",
       ":   253\n",
       "$`3`\n",
       ":   253\n",
       "$`4`\n",
       ":   253\n",
       "$`5`\n",
       ":   253\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$`1`\n",
       "[1] 254\n",
       "\n",
       "$`2`\n",
       "[1] 253\n",
       "\n",
       "$`3`\n",
       "[1] 253\n",
       "\n",
       "$`4`\n",
       "[1] 253\n",
       "\n",
       "$`5`\n",
       "[1] 253\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(index,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34496243",
   "metadata": {},
   "source": [
    "All partitions have roughly the same size. The only partition with one extra observation is the first one.\n",
    "\n",
    "Note that to obtain the length, we used the `lapply` function. The `lapply` function is an extremely powerful function  used to apply a function to each element of a list and return a list as a result. It stands for \"list apply,\" and it is a commonly used function in R for working with lists and vectors. \n",
    "\n",
    "The basic syntax of the lapply function is: `lapply(X, FUN)`, where X is the list or vector that we want to apply the function FUN to, and FUN is the function we want to apply. FUN can be any R function, and it takes a single argument, which will be one of the elements of X. The `lapply` function returns a list, where each element of the list results from applying FUN to a corresponding element of X. In our example above, the list is the `index` element, and the function is `length`, and it returns a list with the lengths of each partition.\n",
    "\n",
    "The `lapply` function is useful when we need to perform the same operation on multiple elements of a list or vector and return a list as a result. It is a convenient alternative to using a for loop, as it is easier to read and write, more efficient for large lists, and faster and easily parallelizable in many circumstances.\n",
    "\n",
    "With the indices, we can then split the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6af2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicar a la lista de folds 1,2,3,4,5\n",
    "splt <- lapply(1:K, function(ind) nlsy[index[[ind]], ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71c6f5",
   "metadata": {},
   "source": [
    "Then the first partition of the matchadata set will be in the first element of the `splt` element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5527e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 994</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>lnw_2016</th><th scope=col>educ</th><th scope=col>black</th><th scope=col>hispanic</th><th scope=col>other</th><th scope=col>exp</th><th scope=col>afqt</th><th scope=col>mom_educ</th><th scope=col>dad_educ</th><th scope=col>yhea_100_1997</th><th scope=col>⋯</th><th scope=col>_XPexp_13</th><th scope=col>_XPexp_14</th><th scope=col>_XPexp_16</th><th scope=col>_XPexp_17</th><th scope=col>_XPexp_18</th><th scope=col>_XPexp_19</th><th scope=col>_XPexp_20</th><th scope=col>_XPexp_21</th><th scope=col>_XPexp_22</th><th scope=col>_XPexp_23</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>4.076898</td><td>16</td><td>0</td><td>0</td><td>0</td><td>11</td><td>7.0724</td><td>12</td><td>12</td><td>3</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>4.711924</td><td>16</td><td>0</td><td>0</td><td>0</td><td>14</td><td>8.9502</td><td>18</td><td>20</td><td>1</td><td>⋯</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>3.547380</td><td>16</td><td>0</td><td>0</td><td>0</td><td>13</td><td>9.0491</td><td>16</td><td>16</td><td>1</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>3.091614</td><td>18</td><td>1</td><td>0</td><td>0</td><td>12</td><td>6.6286</td><td>12</td><td>10</td><td>2</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>3.315900</td><td>16</td><td>0</td><td>0</td><td>0</td><td>15</td><td>8.1152</td><td>13</td><td>13</td><td>2</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>4.772224</td><td>13</td><td>0</td><td>0</td><td>0</td><td>16</td><td>4.7042</td><td>18</td><td>18</td><td>1</td><td>⋯</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 994\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " lnw\\_2016 & educ & black & hispanic & other & exp & afqt & mom\\_educ & dad\\_educ & yhea\\_100\\_1997 & ⋯ & \\_XPexp\\_13 & \\_XPexp\\_14 & \\_XPexp\\_16 & \\_XPexp\\_17 & \\_XPexp\\_18 & \\_XPexp\\_19 & \\_XPexp\\_20 & \\_XPexp\\_21 & \\_XPexp\\_22 & \\_XPexp\\_23\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 4.076898 & 16 & 0 & 0 & 0 & 11 & 7.0724 & 12 & 12 & 3 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 4.711924 & 16 & 0 & 0 & 0 & 14 & 8.9502 & 18 & 20 & 1 & ⋯ & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 3.547380 & 16 & 0 & 0 & 0 & 13 & 9.0491 & 16 & 16 & 1 & ⋯ & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 3.091614 & 18 & 1 & 0 & 0 & 12 & 6.6286 & 12 & 10 & 2 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 3.315900 & 16 & 0 & 0 & 0 & 15 & 8.1152 & 13 & 13 & 2 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 4.772224 & 13 & 0 & 0 & 0 & 16 & 4.7042 & 18 & 18 & 1 & ⋯ & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 994\n",
       "\n",
       "| lnw_2016 &lt;dbl&gt; | educ &lt;dbl&gt; | black &lt;dbl&gt; | hispanic &lt;dbl&gt; | other &lt;dbl&gt; | exp &lt;dbl&gt; | afqt &lt;dbl&gt; | mom_educ &lt;dbl&gt; | dad_educ &lt;dbl&gt; | yhea_100_1997 &lt;dbl&gt; | ⋯ ⋯ | _XPexp_13 &lt;dbl&gt; | _XPexp_14 &lt;dbl&gt; | _XPexp_16 &lt;dbl&gt; | _XPexp_17 &lt;dbl&gt; | _XPexp_18 &lt;dbl&gt; | _XPexp_19 &lt;dbl&gt; | _XPexp_20 &lt;dbl&gt; | _XPexp_21 &lt;dbl&gt; | _XPexp_22 &lt;dbl&gt; | _XPexp_23 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 4.076898 | 16 | 0 | 0 | 0 | 11 | 7.0724 | 12 | 12 | 3 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 4.711924 | 16 | 0 | 0 | 0 | 14 | 8.9502 | 18 | 20 | 1 | ⋯ | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 3.547380 | 16 | 0 | 0 | 0 | 13 | 9.0491 | 16 | 16 | 1 | ⋯ | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 3.091614 | 18 | 1 | 0 | 0 | 12 | 6.6286 | 12 | 10 | 2 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 3.315900 | 16 | 0 | 0 | 0 | 15 | 8.1152 | 13 | 13 | 2 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 4.772224 | 13 | 0 | 0 | 0 | 16 | 4.7042 | 18 | 18 | 1 | ⋯ | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  lnw_2016 educ black hispanic other exp afqt   mom_educ dad_educ yhea_100_1997\n",
       "1 4.076898 16   0     0        0     11  7.0724 12       12       3            \n",
       "2 4.711924 16   0     0        0     14  8.9502 18       20       1            \n",
       "3 3.547380 16   0     0        0     13  9.0491 16       16       1            \n",
       "4 3.091614 18   1     0        0     12  6.6286 12       10       2            \n",
       "5 3.315900 16   0     0        0     15  8.1152 13       13       2            \n",
       "6 4.772224 13   0     0        0     16  4.7042 18       18       1            \n",
       "  ⋯ _XPexp_13 _XPexp_14 _XPexp_16 _XPexp_17 _XPexp_18 _XPexp_19 _XPexp_20\n",
       "1 ⋯ 0         0         0         0         0         0         0        \n",
       "2 ⋯ 0         1         0         0         0         0         0        \n",
       "3 ⋯ 1         0         0         0         0         0         0        \n",
       "4 ⋯ 0         0         0         0         0         0         0        \n",
       "5 ⋯ 0         0         0         0         0         0         0        \n",
       "6 ⋯ 0         0         1         0         0         0         0        \n",
       "  _XPexp_21 _XPexp_22 _XPexp_23\n",
       "1 0         0         0        \n",
       "2 0         0         0        \n",
       "3 0         0         0        \n",
       "4 0         0         0        \n",
       "5 0         0         0        \n",
       "6 0         0         0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(splt[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658596c6",
   "metadata": {},
   "source": [
    "## Fitting the model leaving out one of the folds \n",
    "\n",
    "\n",
    "To fit the model, we will again leverage the power of `lapply`, but first we need the `rbindlist` available in the `data.table` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e87e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_load(data.table)\n",
    "\n",
    "m1 <- lapply(1:K, function(ii) lm(lnw_2016~educ, data = rbindlist(splt[-ii]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738eb459",
   "metadata": {},
   "source": [
    "In the previous step, we fitted the model `lnw_2016~educ` in every fold except the `ii` fold. We achieved this by creating a function that runs a linear regression on a data set constructed by binding all the elements in the `splt` list except the element indexed by `ii`.\n",
    "\n",
    "Next, we fit the model in the fold that was left as a testing fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20dab125",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 <- lapply(1:K, function(ii) data.frame(predict(m1[[ii]], newdata = rbindlist(splt[ii]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66183bde",
   "metadata": {},
   "source": [
    "We can see then that it created a vector with predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1748d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><table class=\"dataframe\">\n",
       "<caption>A data.frame: 254 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>predict.m1..ii....newdata...rbindlist.splt.ii...</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3.358399</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>3.010813</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>2.871779</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>3.427916</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>3.149848</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>3.358399</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>3.358399</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>3.288882</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>2.802262</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>2.802262</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>3.010813</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>3.497433</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>3.497433</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>3.497433</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>3.427916</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>2.663228</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>225</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>226</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>227</th><td>3.010813</td></tr>\n",
       "\t<tr><th scope=row>228</th><td>2.802262</td></tr>\n",
       "\t<tr><th scope=row>229</th><td>3.358399</td></tr>\n",
       "\t<tr><th scope=row>230</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>231</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>232</th><td>2.732745</td></tr>\n",
       "\t<tr><th scope=row>233</th><td>3.010813</td></tr>\n",
       "\t<tr><th scope=row>234</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>235</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>236</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>237</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>238</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>239</th><td>3.149848</td></tr>\n",
       "\t<tr><th scope=row>240</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>241</th><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>242</th><td>2.732745</td></tr>\n",
       "\t<tr><th scope=row>243</th><td>2.871779</td></tr>\n",
       "\t<tr><th scope=row>244</th><td>2.732745</td></tr>\n",
       "\t<tr><th scope=row>245</th><td>3.010813</td></tr>\n",
       "\t<tr><th scope=row>246</th><td>2.802262</td></tr>\n",
       "\t<tr><th scope=row>247</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>248</th><td>3.149848</td></tr>\n",
       "\t<tr><th scope=row>249</th><td>2.941296</td></tr>\n",
       "\t<tr><th scope=row>250</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>251</th><td>2.871779</td></tr>\n",
       "\t<tr><th scope=row>252</th><td>3.080330</td></tr>\n",
       "\t<tr><th scope=row>253</th><td>2.802262</td></tr>\n",
       "\t<tr><th scope=row>254</th><td>2.871779</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item A data.frame: 254 × 1\n",
       "\\begin{tabular}{r|l}\n",
       "  & predict.m1..ii....newdata...rbindlist.splt.ii...\\\\\n",
       "  & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 3.219365\\\\\n",
       "\t2 & 3.219365\\\\\n",
       "\t3 & 3.219365\\\\\n",
       "\t4 & 3.358399\\\\\n",
       "\t5 & 3.219365\\\\\n",
       "\t6 & 3.010813\\\\\n",
       "\t7 & 2.871779\\\\\n",
       "\t8 & 3.219365\\\\\n",
       "\t9 & 2.941296\\\\\n",
       "\t10 & 3.427916\\\\\n",
       "\t11 & 3.149848\\\\\n",
       "\t12 & 3.219365\\\\\n",
       "\t13 & 3.358399\\\\\n",
       "\t14 & 3.358399\\\\\n",
       "\t15 & 3.288882\\\\\n",
       "\t16 & 2.802262\\\\\n",
       "\t17 & 2.941296\\\\\n",
       "\t18 & 2.802262\\\\\n",
       "\t19 & 3.010813\\\\\n",
       "\t20 & 3.497433\\\\\n",
       "\t21 & 3.497433\\\\\n",
       "\t22 & 2.941296\\\\\n",
       "\t23 & 3.080330\\\\\n",
       "\t24 & 3.497433\\\\\n",
       "\t25 & 2.941296\\\\\n",
       "\t26 & 2.941296\\\\\n",
       "\t27 & 3.427916\\\\\n",
       "\t28 & 2.663228\\\\\n",
       "\t29 & 2.941296\\\\\n",
       "\t30 & 3.080330\\\\\n",
       "\t⋮ & ⋮\\\\\n",
       "\t225 & 3.080330\\\\\n",
       "\t226 & 2.941296\\\\\n",
       "\t227 & 3.010813\\\\\n",
       "\t228 & 2.802262\\\\\n",
       "\t229 & 3.358399\\\\\n",
       "\t230 & 2.941296\\\\\n",
       "\t231 & 2.941296\\\\\n",
       "\t232 & 2.732745\\\\\n",
       "\t233 & 3.010813\\\\\n",
       "\t234 & 2.941296\\\\\n",
       "\t235 & 2.941296\\\\\n",
       "\t236 & 3.080330\\\\\n",
       "\t237 & 3.080330\\\\\n",
       "\t238 & 2.941296\\\\\n",
       "\t239 & 3.149848\\\\\n",
       "\t240 & 3.080330\\\\\n",
       "\t241 & 3.219365\\\\\n",
       "\t242 & 2.732745\\\\\n",
       "\t243 & 2.871779\\\\\n",
       "\t244 & 2.732745\\\\\n",
       "\t245 & 3.010813\\\\\n",
       "\t246 & 2.802262\\\\\n",
       "\t247 & 3.080330\\\\\n",
       "\t248 & 3.149848\\\\\n",
       "\t249 & 2.941296\\\\\n",
       "\t250 & 3.080330\\\\\n",
       "\t251 & 2.871779\\\\\n",
       "\t252 & 3.080330\\\\\n",
       "\t253 & 2.802262\\\\\n",
       "\t254 & 2.871779\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. \n",
       "A data.frame: 254 × 1\n",
       "\n",
       "| <!--/--> | predict.m1..ii....newdata...rbindlist.splt.ii... &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 1 | 3.219365 |\n",
       "| 2 | 3.219365 |\n",
       "| 3 | 3.219365 |\n",
       "| 4 | 3.358399 |\n",
       "| 5 | 3.219365 |\n",
       "| 6 | 3.010813 |\n",
       "| 7 | 2.871779 |\n",
       "| 8 | 3.219365 |\n",
       "| 9 | 2.941296 |\n",
       "| 10 | 3.427916 |\n",
       "| 11 | 3.149848 |\n",
       "| 12 | 3.219365 |\n",
       "| 13 | 3.358399 |\n",
       "| 14 | 3.358399 |\n",
       "| 15 | 3.288882 |\n",
       "| 16 | 2.802262 |\n",
       "| 17 | 2.941296 |\n",
       "| 18 | 2.802262 |\n",
       "| 19 | 3.010813 |\n",
       "| 20 | 3.497433 |\n",
       "| 21 | 3.497433 |\n",
       "| 22 | 2.941296 |\n",
       "| 23 | 3.080330 |\n",
       "| 24 | 3.497433 |\n",
       "| 25 | 2.941296 |\n",
       "| 26 | 2.941296 |\n",
       "| 27 | 3.427916 |\n",
       "| 28 | 2.663228 |\n",
       "| 29 | 2.941296 |\n",
       "| 30 | 3.080330 |\n",
       "| ⋮ | ⋮ |\n",
       "| 225 | 3.080330 |\n",
       "| 226 | 2.941296 |\n",
       "| 227 | 3.010813 |\n",
       "| 228 | 2.802262 |\n",
       "| 229 | 3.358399 |\n",
       "| 230 | 2.941296 |\n",
       "| 231 | 2.941296 |\n",
       "| 232 | 2.732745 |\n",
       "| 233 | 3.010813 |\n",
       "| 234 | 2.941296 |\n",
       "| 235 | 2.941296 |\n",
       "| 236 | 3.080330 |\n",
       "| 237 | 3.080330 |\n",
       "| 238 | 2.941296 |\n",
       "| 239 | 3.149848 |\n",
       "| 240 | 3.080330 |\n",
       "| 241 | 3.219365 |\n",
       "| 242 | 2.732745 |\n",
       "| 243 | 2.871779 |\n",
       "| 244 | 2.732745 |\n",
       "| 245 | 3.010813 |\n",
       "| 246 | 2.802262 |\n",
       "| 247 | 3.080330 |\n",
       "| 248 | 3.149848 |\n",
       "| 249 | 2.941296 |\n",
       "| 250 | 3.080330 |\n",
       "| 251 | 2.871779 |\n",
       "| 252 | 3.080330 |\n",
       "| 253 | 2.802262 |\n",
       "| 254 | 2.871779 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "    predict.m1..ii....newdata...rbindlist.splt.ii...\n",
       "1                                           3.219365\n",
       "2                                           3.219365\n",
       "3                                           3.219365\n",
       "4                                           3.358399\n",
       "5                                           3.219365\n",
       "6                                           3.010813\n",
       "7                                           2.871779\n",
       "8                                           3.219365\n",
       "9                                           2.941296\n",
       "10                                          3.427916\n",
       "11                                          3.149848\n",
       "12                                          3.219365\n",
       "13                                          3.358399\n",
       "14                                          3.358399\n",
       "15                                          3.288882\n",
       "16                                          2.802262\n",
       "17                                          2.941296\n",
       "18                                          2.802262\n",
       "19                                          3.010813\n",
       "20                                          3.497433\n",
       "21                                          3.497433\n",
       "22                                          2.941296\n",
       "23                                          3.080330\n",
       "24                                          3.497433\n",
       "25                                          2.941296\n",
       "26                                          2.941296\n",
       "27                                          3.427916\n",
       "28                                          2.663228\n",
       "29                                          2.941296\n",
       "30                                          3.080330\n",
       "31                                          3.010813\n",
       "32                                          3.149848\n",
       "33                                          3.497433\n",
       "34                                          3.497433\n",
       "35                                          3.219365\n",
       "36                                          2.941296\n",
       "37                                          2.941296\n",
       "38                                          2.941296\n",
       "39                                          3.358399\n",
       "40                                          3.080330\n",
       "41                                          3.080330\n",
       "42                                          3.358399\n",
       "43                                          3.497433\n",
       "44                                          3.219365\n",
       "45                                          3.080330\n",
       "46                                          3.427916\n",
       "47                                          3.288882\n",
       "48                                          3.358399\n",
       "49                                          3.219365\n",
       "50                                          3.427916\n",
       "51                                          3.010813\n",
       "52                                          3.427916\n",
       "53                                          3.288882\n",
       "54                                          3.219365\n",
       "55                                          3.288882\n",
       "56                                          3.288882\n",
       "57                                          3.219365\n",
       "58                                          3.497433\n",
       "59                                          3.427916\n",
       "60                                          3.080330\n",
       "61                                          3.427916\n",
       "62                                          3.219365\n",
       "63                                          3.358399\n",
       "64                                          3.219365\n",
       "65                                          3.219365\n",
       "66                                          3.358399\n",
       "67                                          3.358399\n",
       "68                                          3.219365\n",
       "69                                          3.427916\n",
       "70                                          3.358399\n",
       "71                                          3.080330\n",
       "72                                          3.080330\n",
       "73                                          3.358399\n",
       "74                                          3.288882\n",
       "75                                          2.663228\n",
       "76                                          3.427916\n",
       "77                                          3.358399\n",
       "78                                          3.427916\n",
       "79                                          3.427916\n",
       "80                                          3.427916\n",
       "81                                          3.497433\n",
       "82                                          3.427916\n",
       "83                                          3.497433\n",
       "84                                          3.358399\n",
       "85                                          3.219365\n",
       "86                                          3.427916\n",
       "87                                          3.288882\n",
       "88                                          3.358399\n",
       "89                                          3.358399\n",
       "90                                          3.288882\n",
       "91                                          3.149848\n",
       "92                                          3.219365\n",
       "93                                          3.219365\n",
       "94                                          3.497433\n",
       "95                                          3.497433\n",
       "96                                          3.288882\n",
       "97                                          3.358399\n",
       "98                                          3.358399\n",
       "99                                          3.010813\n",
       "100                                         3.080330\n",
       "101                                         3.010813\n",
       "102                                         3.219365\n",
       "103                                         2.941296\n",
       "104                                         3.219365\n",
       "105                                         3.080330\n",
       "106                                         3.080330\n",
       "107                                         3.149848\n",
       "108                                         3.358399\n",
       "109                                         2.941296\n",
       "110                                         2.871779\n",
       "111                                         3.149848\n",
       "112                                         2.941296\n",
       "113                                         2.941296\n",
       "114                                         3.010813\n",
       "115                                         3.080330\n",
       "116                                         3.010813\n",
       "117                                         3.080330\n",
       "118                                         3.149848\n",
       "119                                         3.219365\n",
       "120                                         2.941296\n",
       "121                                         3.219365\n",
       "122                                         2.802262\n",
       "123                                         2.871779\n",
       "124                                         2.871779\n",
       "125                                         2.941296\n",
       "126                                         3.080330\n",
       "127                                         3.288882\n",
       "128                                         3.219365\n",
       "129                                         3.010813\n",
       "130                                         3.219365\n",
       "131                                         3.080330\n",
       "132                                         2.941296\n",
       "133                                         3.219365\n",
       "134                                         2.663228\n",
       "135                                         3.219365\n",
       "136                                         3.358399\n",
       "137                                         2.941296\n",
       "138                                         3.010813\n",
       "139                                         3.219365\n",
       "140                                         2.871779\n",
       "141                                         2.941296\n",
       "142                                         3.010813\n",
       "143                                         3.219365\n",
       "144                                         3.219365\n",
       "145                                         3.288882\n",
       "146                                         2.732745\n",
       "147                                         2.871779\n",
       "148                                         3.288882\n",
       "149                                         3.149848\n",
       "150                                         3.010813\n",
       "151                                         2.941296\n",
       "152                                         3.149848\n",
       "153                                         3.288882\n",
       "154                                         3.080330\n",
       "155                                         2.941296\n",
       "156                                         2.941296\n",
       "157                                         3.288882\n",
       "158                                         2.941296\n",
       "159                                         3.149848\n",
       "160                                         3.080330\n",
       "161                                         2.871779\n",
       "162                                         3.080330\n",
       "163                                         3.080330\n",
       "164                                         3.080330\n",
       "165                                         3.149848\n",
       "166                                         3.080330\n",
       "167                                         3.219365\n",
       "168                                         3.219365\n",
       "169                                         3.149848\n",
       "170                                         3.219365\n",
       "171                                         2.941296\n",
       "172                                         2.941296\n",
       "173                                         2.663228\n",
       "174                                         2.732745\n",
       "175                                         2.941296\n",
       "176                                         2.941296\n",
       "177                                         2.802262\n",
       "178                                         2.941296\n",
       "179                                         2.941296\n",
       "180                                         3.010813\n",
       "181                                         2.941296\n",
       "182                                         2.941296\n",
       "183                                         2.941296\n",
       "184                                         2.941296\n",
       "185                                         2.941296\n",
       "186                                         3.288882\n",
       "187                                         2.941296\n",
       "188                                         2.732745\n",
       "189                                         2.871779\n",
       "190                                         3.010813\n",
       "191                                         2.663228\n",
       "192                                         2.871779\n",
       "193                                         2.871779\n",
       "194                                         3.010813\n",
       "195                                         3.219365\n",
       "196                                         3.080330\n",
       "197                                         2.941296\n",
       "198                                         2.941296\n",
       "199                                         2.941296\n",
       "200                                         2.663228\n",
       "201                                         3.080330\n",
       "202                                         2.941296\n",
       "203                                         2.941296\n",
       "204                                         2.871779\n",
       "205                                         2.802262\n",
       "206                                         3.080330\n",
       "207                                         2.941296\n",
       "208                                         2.663228\n",
       "209                                         2.802262\n",
       "210                                         3.219365\n",
       "211                                         2.871779\n",
       "212                                         2.941296\n",
       "213                                         2.732745\n",
       "214                                         2.941296\n",
       "215                                         2.941296\n",
       "216                                         3.427916\n",
       "217                                         2.941296\n",
       "218                                         2.732745\n",
       "219                                         3.080330\n",
       "220                                         2.941296\n",
       "221                                         2.941296\n",
       "222                                         2.663228\n",
       "223                                         2.941296\n",
       "224                                         3.010813\n",
       "225                                         3.080330\n",
       "226                                         2.941296\n",
       "227                                         3.010813\n",
       "228                                         2.802262\n",
       "229                                         3.358399\n",
       "230                                         2.941296\n",
       "231                                         2.941296\n",
       "232                                         2.732745\n",
       "233                                         3.010813\n",
       "234                                         2.941296\n",
       "235                                         2.941296\n",
       "236                                         3.080330\n",
       "237                                         3.080330\n",
       "238                                         2.941296\n",
       "239                                         3.149848\n",
       "240                                         3.080330\n",
       "241                                         3.219365\n",
       "242                                         2.732745\n",
       "243                                         2.871779\n",
       "244                                         2.732745\n",
       "245                                         3.010813\n",
       "246                                         2.802262\n",
       "247                                         3.080330\n",
       "248                                         3.149848\n",
       "249                                         2.941296\n",
       "250                                         3.080330\n",
       "251                                         2.871779\n",
       "252                                         3.080330\n",
       "253                                         2.802262\n",
       "254                                         2.871779\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(p1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1c44f",
   "metadata": {},
   "source": [
    "Now we bind this vector to each fold so we have extra column in each fold with the prediction, named `yhat`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81e8b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 1:K) {\n",
    "  colnames(p1[[i]])<-\"yhat\" #change the name\n",
    "  splt[[i]] <- cbind(splt[[i]], p1[[i]])\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d59ef929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 995</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>lnw_2016</th><th scope=col>educ</th><th scope=col>black</th><th scope=col>hispanic</th><th scope=col>other</th><th scope=col>exp</th><th scope=col>afqt</th><th scope=col>mom_educ</th><th scope=col>dad_educ</th><th scope=col>yhea_100_1997</th><th scope=col>⋯</th><th scope=col>_XPexp_14</th><th scope=col>_XPexp_16</th><th scope=col>_XPexp_17</th><th scope=col>_XPexp_18</th><th scope=col>_XPexp_19</th><th scope=col>_XPexp_20</th><th scope=col>_XPexp_21</th><th scope=col>_XPexp_22</th><th scope=col>_XPexp_23</th><th scope=col>yhat</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>4.076898</td><td>16</td><td>0</td><td>0</td><td>0</td><td>11</td><td>7.0724</td><td>12</td><td>12</td><td>3</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>4.711924</td><td>16</td><td>0</td><td>0</td><td>0</td><td>14</td><td>8.9502</td><td>18</td><td>20</td><td>1</td><td>⋯</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3.547380</td><td>16</td><td>0</td><td>0</td><td>0</td><td>13</td><td>9.0491</td><td>16</td><td>16</td><td>1</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3.091614</td><td>18</td><td>1</td><td>0</td><td>0</td><td>12</td><td>6.6286</td><td>12</td><td>10</td><td>2</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3.358399</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3.315900</td><td>16</td><td>0</td><td>0</td><td>0</td><td>15</td><td>8.1152</td><td>13</td><td>13</td><td>2</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3.219365</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>4.772224</td><td>13</td><td>0</td><td>0</td><td>0</td><td>16</td><td>4.7042</td><td>18</td><td>18</td><td>1</td><td>⋯</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3.010813</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 995\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & lnw\\_2016 & educ & black & hispanic & other & exp & afqt & mom\\_educ & dad\\_educ & yhea\\_100\\_1997 & ⋯ & \\_XPexp\\_14 & \\_XPexp\\_16 & \\_XPexp\\_17 & \\_XPexp\\_18 & \\_XPexp\\_19 & \\_XPexp\\_20 & \\_XPexp\\_21 & \\_XPexp\\_22 & \\_XPexp\\_23 & yhat\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 4.076898 & 16 & 0 & 0 & 0 & 11 & 7.0724 & 12 & 12 & 3 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3.219365\\\\\n",
       "\t2 & 4.711924 & 16 & 0 & 0 & 0 & 14 & 8.9502 & 18 & 20 & 1 & ⋯ & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3.219365\\\\\n",
       "\t3 & 3.547380 & 16 & 0 & 0 & 0 & 13 & 9.0491 & 16 & 16 & 1 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3.219365\\\\\n",
       "\t4 & 3.091614 & 18 & 1 & 0 & 0 & 12 & 6.6286 & 12 & 10 & 2 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3.358399\\\\\n",
       "\t5 & 3.315900 & 16 & 0 & 0 & 0 & 15 & 8.1152 & 13 & 13 & 2 & ⋯ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3.219365\\\\\n",
       "\t6 & 4.772224 & 13 & 0 & 0 & 0 & 16 & 4.7042 & 18 & 18 & 1 & ⋯ & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 3.010813\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 995\n",
       "\n",
       "| <!--/--> | lnw_2016 &lt;dbl&gt; | educ &lt;dbl&gt; | black &lt;dbl&gt; | hispanic &lt;dbl&gt; | other &lt;dbl&gt; | exp &lt;dbl&gt; | afqt &lt;dbl&gt; | mom_educ &lt;dbl&gt; | dad_educ &lt;dbl&gt; | yhea_100_1997 &lt;dbl&gt; | ⋯ ⋯ | _XPexp_14 &lt;dbl&gt; | _XPexp_16 &lt;dbl&gt; | _XPexp_17 &lt;dbl&gt; | _XPexp_18 &lt;dbl&gt; | _XPexp_19 &lt;dbl&gt; | _XPexp_20 &lt;dbl&gt; | _XPexp_21 &lt;dbl&gt; | _XPexp_22 &lt;dbl&gt; | _XPexp_23 &lt;dbl&gt; | yhat &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 4.076898 | 16 | 0 | 0 | 0 | 11 | 7.0724 | 12 | 12 | 3 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3.219365 |\n",
       "| 2 | 4.711924 | 16 | 0 | 0 | 0 | 14 | 8.9502 | 18 | 20 | 1 | ⋯ | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3.219365 |\n",
       "| 3 | 3.547380 | 16 | 0 | 0 | 0 | 13 | 9.0491 | 16 | 16 | 1 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3.219365 |\n",
       "| 4 | 3.091614 | 18 | 1 | 0 | 0 | 12 | 6.6286 | 12 | 10 | 2 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3.358399 |\n",
       "| 5 | 3.315900 | 16 | 0 | 0 | 0 | 15 | 8.1152 | 13 | 13 | 2 | ⋯ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3.219365 |\n",
       "| 6 | 4.772224 | 13 | 0 | 0 | 0 | 16 | 4.7042 | 18 | 18 | 1 | ⋯ | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3.010813 |\n",
       "\n"
      ],
      "text/plain": [
       "  lnw_2016 educ black hispanic other exp afqt   mom_educ dad_educ yhea_100_1997\n",
       "1 4.076898 16   0     0        0     11  7.0724 12       12       3            \n",
       "2 4.711924 16   0     0        0     14  8.9502 18       20       1            \n",
       "3 3.547380 16   0     0        0     13  9.0491 16       16       1            \n",
       "4 3.091614 18   1     0        0     12  6.6286 12       10       2            \n",
       "5 3.315900 16   0     0        0     15  8.1152 13       13       2            \n",
       "6 4.772224 13   0     0        0     16  4.7042 18       18       1            \n",
       "  ⋯ _XPexp_14 _XPexp_16 _XPexp_17 _XPexp_18 _XPexp_19 _XPexp_20 _XPexp_21\n",
       "1 ⋯ 0         0         0         0         0         0         0        \n",
       "2 ⋯ 1         0         0         0         0         0         0        \n",
       "3 ⋯ 0         0         0         0         0         0         0        \n",
       "4 ⋯ 0         0         0         0         0         0         0        \n",
       "5 ⋯ 0         0         0         0         0         0         0        \n",
       "6 ⋯ 0         1         0         0         0         0         0        \n",
       "  _XPexp_22 _XPexp_23 yhat    \n",
       "1 0         0         3.219365\n",
       "2 0         0         3.219365\n",
       "3 0         0         3.219365\n",
       "4 0         0         3.358399\n",
       "5 0         0         3.219365\n",
       "6 0         0         3.010813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(splt[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d2d3e",
   "metadata": {},
   "source": [
    "\n",
    "## Calculating the MSE\n",
    "\n",
    "\n",
    "Finally, we need to calculate the  CV(k) estimate for the test MSE. We know that it takes the form:\n",
    "\n",
    "\\begin{align}\n",
    "CV_{(k)} &= \\frac{1}{k}\\sum_{j=1}^k MSE_j \\\\\n",
    "         &= \\frac{1}{k}\\sum_{j=1}^k (y_j^k-\\hat{y}_{-k})^{2}\n",
    "\\end{align}\n",
    "\n",
    "To implment this formula we first need to calculate the MSE for each fold using `lapply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1879c2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>0.95177623749833</li>\n",
       "\t<li>0.56746996007526</li>\n",
       "\t<li>0.718195582349171</li>\n",
       "\t<li>0.826306431325315</li>\n",
       "\t<li>0.470351830572554</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item 0.95177623749833\n",
       "\\item 0.56746996007526\n",
       "\\item 0.718195582349171\n",
       "\\item 0.826306431325315\n",
       "\\item 0.470351830572554\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 0.95177623749833\n",
       "2. 0.56746996007526\n",
       "3. 0.718195582349171\n",
       "4. 0.826306431325315\n",
       "5. 0.470351830572554\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] 0.9517762\n",
       "\n",
       "[[2]]\n",
       "[1] 0.56747\n",
       "\n",
       "[[3]]\n",
       "[1] 0.7181956\n",
       "\n",
       "[[4]]\n",
       "[1] 0.8263064\n",
       "\n",
       "[[5]]\n",
       "[1] 0.4703518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE2_k <- lapply(1:K, function(ii) mean((splt[[ii]]$lnw_2016 - splt[[ii]]$yhat)^2))\n",
    "MSE2_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ef1cd",
   "metadata": {},
   "source": [
    "And finally, calculate the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85b1e908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.706820008364126"
      ],
      "text/latex": [
       "0.706820008364126"
      ],
      "text/markdown": [
       "0.706820008364126"
      ],
      "text/plain": [
       "[1] 0.70682"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(unlist(MSE2_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec3313",
   "metadata": {},
   "source": [
    "Note that since `lapply` always return a list, to be able to average the results, we first unlisted the object and then calculated the `mean`.\n",
    "\n",
    "Finally, we can compare the results to that obtained using only the validation set approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b50ef750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.840725881821255"
      ],
      "text/latex": [
       "0.840725881821255"
      ],
      "text/markdown": [
       "0.840725881821255"
      ],
      "text/plain": [
       "[1] 0.8407259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt(mean(unlist(MSE2_k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec1d605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.892188320927819"
      ],
      "text/latex": [
       "0.892188320927819"
      ],
      "text/markdown": [
       "0.892188320927819"
      ],
      "text/plain": [
       "[1] 0.8921883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt(db$MSE[db$model==\"model2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b31157",
   "metadata": {},
   "source": [
    "## With Caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11c24825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: caret\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(\"caret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecdce280",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(0101)\n",
    "ctrl <- trainControl(\n",
    "  method = \"cv\",  # crossvalidation\n",
    "    number = 5) # número de folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f5d099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear Regression \n",
       "\n",
       "1266 samples\n",
       "   1 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (5 fold) \n",
       "Summary of sample sizes: 1012, 1014, 1014, 1012, 1012 \n",
       "Resampling results:\n",
       "\n",
       "  RMSE       Rsquared    MAE      \n",
       "  0.8387328  0.07150229  0.5624656\n",
       "\n",
       "Tuning parameter 'intercept' was held constant at a value of TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo2caret <- train(lnw_2016~educ, \n",
    "                  data = nlsy, \n",
    "                  method = 'lm',\n",
    "                  trControl= ctrl )\n",
    "\n",
    "modelo2caret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8d131",
   "metadata": {},
   "source": [
    "If I want to implement LOOCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "663e88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    }
   ],
   "source": [
    "ctrl_loocv <- trainControl(\n",
    "  method = \"loocv\")\n",
    "\n",
    "modelo2caret_loocv <- train(lnw_2016~educ, \n",
    "                  data = nlsy, \n",
    "                  method = 'lm',\n",
    "                  trControl= ctrl_loocv )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0f723da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear Regression \n",
       "\n",
       "1266 samples\n",
       "   1 predictor\n",
       "\n",
       "No pre-processing\n",
       "Resampling: Leave-One-Out Cross-Validation \n",
       "Summary of sample sizes: 1265, 1265, 1265, 1265, 1265, 1265, ... \n",
       "Resampling results:\n",
       "\n",
       "  RMSE       Rsquared  MAE      \n",
       "  0.5630921  NaN       0.5630921\n",
       "\n",
       "Tuning parameter 'intercept' was held constant at a value of TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo2caret_loocv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89befb",
   "metadata": {},
   "source": [
    "\n",
    "# If we have enough data\n",
    "\n",
    "\n",
    "In some cases, where there's enough data, researchers may use both K-Fold Cross-Validation and the validation set approach in combination to evaluate the performance of a machine learning model. This can be useful when a researcher wants to obtain a more robust evaluation of the model's performance while maintaining computational efficiency.\n",
    "\n",
    "The following figure shows the strategy followed by Kleinberg et al. (2017) in their paper \"Human decisions and machine predictions\":\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"human_decisions.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "This strategy prevents the machine learning algorithm from appearing to do well simply because it is being evaluated on data it has already seen. Moreover, they add an extra layer of protection to ensure that the results are not an artifact of unhelpful \"human data mining,\" adding a \"pure hold-out.\"\n",
    "\n",
    "By combining K-Fold Cross-Validation and the validation set approach, researchers can obtain a more comprehensive evaluation of the model's performance while maintaining computational efficiency. The specific combination of K-Fold Cross-Validation and the validation set approach will depend on the researcher's goals and the particular constraints of the study. When choosing a resampling technique, it is essential to carefully consider the trade-offs between computational efficiency and thoroughness.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
